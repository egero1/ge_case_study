\subsection{Generalized Linear Model} 

Generalized Linear Models are an extension of linear regression that allow for the response variable to have a non-normal distribution. Having a binary response variable, the relationship between the predictors and the response variable is not linear, so the logit link function is used to provide a transformation and ensure that the response is constrained between 0 and 1. The logit function is defined as: $$logit(p) =log\frac{p}{1-p}$$

```{r glm_model, echo = FALSE}

# Create a data frame to hold the results
glm_results <- data.frame(Model = character()
                          ,Data = character()
                          ,Accuracy = numeric()
                          ,Sensitivity = numeric()
                          ,Specificity = numeric()
                          ,Precision = numeric()
                          ,Kappa = numeric()
                          ,F1 = numeric()
                          ,ROC = numeric())
```

```{r glm_models, echo = FALSE}
###############################################################################
# Generalized Linear Models
###############################################################################

# Enable parallel processing and reserve resources
#cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
#registerDoParallel(cluster)

# Set up training conditions - must use LOOCV
fitControl <- trainControl(method = "LOOCV"
                           ,classProbs = TRUE 
                           ,summaryFunction = twoClassSummary
                           ,savePredictions = 'final')

# Full data set
#set.seed(1234)
#glm.model.ud <- caret::train(Label ~.
#                          ,data = use_data
#                          ,family = 'binomial'
#                          ,method = 'glm'
#                          ,trControl = fitControl
#                          ,metric = "ROC")

glm.model.ud <- readRDS('../../Models/glm_use_data.rds')

# Get the confusion matrix
glm.cm.ud <- caret::confusionMatrix(glm.model.ud$pred$pred, glm.model.ud$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(glm.model.ud)
glm_results <- rbind(glm_results
                        ,data.frame(Model = 'GLM'
                        ,Data = 'Full'
                        ,Accuracy = glm.cm.ud$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = glm.cm.ud$byClass[5]
                        ,Kappa = glm.cm.ud$overall[2]
                        ,F1 = glm.cm.ud$byClass[7]
                        ,ROC = performance[,1]
                        ))

# RFE selection data set
#set.seed(1234)
#glm.model.md <- caret::train(Label ~.
#                          ,data = model_data
#                          ,family = 'binomial'
#                          ,method = 'glm'
#                          ,trControl = fitControl
#                          ,metric = "ROC")

glm.model.md <- readRDS('../../Models/glm_model_data.rds')

# Get the confusion matrix
glm.cm.md <- caret::confusionMatrix(glm.model.md$pred$pred, glm.model.md$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(glm.model.md)
glm_results <- rbind(glm_results
                        ,data.frame(Model = 'GLM'
                        ,Data = 'RFE Selection'
                        ,Accuracy = glm.cm.md$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = glm.cm.md$byClass[5]
                        ,Kappa = glm.cm.md$overall[2]
                        ,F1 = glm.cm.md$byClass[7]
                        ,ROC = performance[,1]))

# Low correlation data set
#set.seed(1234)
#glm.model.lc <- caret::train(Label ~.
#                          ,data = use_data_lc
#                          ,family = 'binomial'
#                          ,method = 'glm'
#                          ,trControl = fitControl
#                          ,metric = "ROC")

glm.model.lc <- readRDS('../../Models/glm_use_data_lc.rds')

# Get the confusion matrix
glm.cm.lc <- caret::confusionMatrix(glm.model.lc$pred$pred, glm.model.lc$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(glm.model.lc)
glm_results <- rbind(glm_results
                        ,data.frame(Model = 'GLM'
                        ,Data = 'Low Correlation'
                        ,Accuracy = glm.cm.lc$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = glm.cm.lc$byClass[5]
                        ,Kappa = glm.cm.lc$overall[2]
                        ,F1 = glm.cm.lc$byClass[7]
                        ,ROC = performance[,1]))

rownames(glm_results) <- NULL

# Disable parallel processing and release resources
#stopCluster(cluster)
#registerDoSEQ()

```

The evaluation metrics for the GLM models are available in __Table 8__. The full data set has a slight edge here with an accuracy of `r round(glm.cm.ud$overall[1] * 100, 2)`%. All other metrics agree that the model performs slightly better as well, which is not always the case.

```{r glm_results, echo = FALSE}

kable(glm_results, caption = "GLM Model Results", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))
```

The confusion matrix for this model is available in __Table 9__. While the model is not performing poorly, it is only slightly better than the naive model and predicts Pneumoconiosis in 105 patients when no disease is actually present; this is known as at type I error. The model also fails to predict the presence of Pneumoconiosis in 139 patients; this is a type II error.

```{r glm_table, echo = FALSE}

kable(glm.cm.ud$table, caption = "GLM Model Confusion Matrix", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))

glm.ROC <- roc(glm.model.ud$pred$obs, glm.model.ud$pred$Normal)
glm.auc <- auc(glm.ROC)

```

The AUC in __Figure 9__ of `r glm.auc` is slightly misleading given a model accuracy of `r round(glm.cm.ud$overall[1] * 100, 2)`%. For classification, no single evaluation metric tells the whole story, so it is always best to review several. The 'confusionMatrix' function in the 'caret' package makes generating all necessary evaluation metrics relatively easy.

```{r glm_roc, echo = FALSE, out.width = '350px', fig.cap = 'GLM ROC Curve', fig.align = "center", fig.pos = 'H'}

plot(glm.ROC, col = 'blue', main = paste('GLM - Area under the curve (AUC):', round(auc(glm.ROC),2)))

```

Lastly, since GLM is extension of linear regression, the regression coefficients are available for the model in __Table 10__. To conserve space, only the first 10 are listed here. The full list of coefficients may be generated for further review if required.

```{r glm_coefficients, echo = FALSE}
# Print model coefficients
coefficients <- as.data.frame(glm.model.ud$finalModel$coefficients)
coefficients$Variable <- rownames(coefficients)
coefficients <- coefficients[c(2,1)]
rownames(coefficients) <- NULL
colnames(coefficients) <- c('Variable', 'Coefficient')

kable(coefficients[1:10,], caption = "GLM Model Coefficients", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))

```

