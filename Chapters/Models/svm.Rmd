\subsection{Support Vector Machine} 

A Support Vector Machine (SVM) is a supervised machine learning algorithm defined by a separating hyperplane. In this algorithm, each data element is plotted in n-dimensional space, where is the number of features. Then classification is performed by finding the hyperplane that best differentiates the classes[@ray_2017]. SVM is a very popular modeling techhinque that often provides great results with very little tuning.

A radial basis function kernel (RBF) was selected to classify since the data is not linearly separable. The RBF is defined as:

$$f(x)=\sum_{i}^{N}\alpha _{i}y_{i} exp(-\left \| x-x_{i} \right \|^{2}/2\sigma ^2) + b$$
The main take away is that a wider or softer margin is created when C is decreased and that for larger values of $\sigma$ the decision boundary tends to be smoother and more flexible. It also tends to misclassify more often, but reduces the likelihood of overfitting the model [@wang_2014].

```{svm_boundary, echo = FALSE}

vars <- model_data[,c('Hist_2_150_2_Entropy', 'Hist_2_30_2_Entropy', 'Label')]
fitControl = trainControl(classProbs = TRUE)

set.seed(123)
impVars <- train(Label ~ .,
                 data = vars,
                 method = "svmRadial",
                 gamma = 1,
                 importance = TRUE,
                 trControl = fitControl)

```

```{r svm_bound_plot, echo = FALSE, out.width = '350px', fig.cap = 'Decision Boundaries', fig.align = "center", fig.pos = 'H'}

decisionplot <- function(model, data1, data2, class = NULL, predict_type = "class",
                         resolution = 100, showgrid = TRUE, ...) {
        
       # if(!is.null(class)) cl <- data[,class] else cl <- 1
        cl <- class
        data <- data.frame(data1, data2)
        #data <- data[, 1:2]
        k <- length(unique(cl))
        
        plot(data, col = as.integer(cl)+1L, pch = as.integer(cl)+1L, ...)
        legend("top", legend = unique(cl), horiz = TRUE, 
               col = as.integer(unique(cl))+1L, pch = as.integer(unique(cl))+1L)
        
        # make grid
        r <- sapply(data, range, na.rm = TRUE)
        xs <- seq(r[1,1], r[2,1], length.out = resolution)
        ys <- seq(r[1,2], r[2,2], length.out = resolution)
        g <- cbind(rep(xs, each=resolution), rep(ys, time = resolution))
        colnames(g) <- colnames(r)
        g <- as.data.frame(g)
        
        ### guess how to get class labels from predict
        ### (unfortunately not very consistent between models)
        p <- predict(model, g, type = predict_type)
        if(is.list(p)) p <- p$class
        p <- as.factor(p)
        
        if(showgrid) points(g, col = as.integer(p)+1L, pch = ".")
        
        z <- matrix(as.integer(p), nrow = resolution, byrow = TRUE)
        contour(xs, ys, z, add = TRUE, drawlabels = FALSE,
                lwd = 1, levels = (1:(k-1))+.5)
        
        invisible(z)
}

decisionplot(model = impVars, data1 = model_data['Hist_2_150_2_Entropy'], data2 = vars[,2], class = "Label", main = "SVM: Important Variables", predict_type = "raw")

```

```{r svm_results, echo = FALSE}

# Create a data frame to hold the results
svm_results <- data.frame(Model = character()
                             ,Data = character()
                             ,Accuracy = numeric()
                             ,Kappa = numeric()
                             ,F1 = numeric()
                             ,ROC = numeric()
                             ,Sensitivity = numeric()
                             ,Specificity = numeric())
```

```{r svm_models, echo = FALSE}
# Enable parallel processing and reserve resources
#cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
#registerDoParallel(cluster)


# Set up training conditions - must use LOOCV
fitControl <- trainControl(method = "LOOCV"
                           ,classProbs = TRUE 
                           ,summaryFunction = twoClassSummary
                           ,savePredictions = 'final')

# Full data set
#set.seed(1234)
#svm.model.ud <- caret::train(Label ~ .
#                          ,data = use_data 
#                          ,method = "svmRadial"
#                          ,trControl = fitControl
#                          ,metric = "Accuracy")

svm.model.ud <- readRDS('../../Models/svm_use_data.rds')

# Get the confusion matrix
svm.cm.ud <- caret::confusionMatrix(svm.model.ud$pred$pred, svm.model.ud$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.ud)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'Full'
                        ,Accuracy = svm.cm.ud$overall[1]
                        ,Kappa = svm.cm.ud$overall[2]
                        ,F1 = svm.cm.ud$byClass[7]
                        ,ROC = performance[,1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]))

# RFE selection data set
#set.seed(1234)
#svm.model.md <- caret::train(Label ~ .
#                          ,data = model_data
#                          ,method = "svmRadial"
#                          ,trControl = fitControl
#                          ,metric = "Accuracy")

svm.model.md <- readRDS('../../Models/svm_model_data.rds')

# Get the confusion matrix
svm.cm.md <- caret::confusionMatrix(svm.model.md$pred$pred, svm.model.md$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.md)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'RFE Selection'
                        ,Accuracy = svm.cm.md$overall[1]
                        ,Kappa = svm.cm.md$overall[2]
                        ,F1 = svm.cm.md$byClass[7]
                        ,ROC = performance[,1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]))

# Low correlation data set
#set.seed(1234)
#svm.model.lc <- caret::train(Label ~ .
#                           ,data = use_data_lc
#                           ,method = "svmRadial"
#                           ,trControl = fitControl
#                           ,metric = "Accuracy")

svm.model.lc <- readRDS('../../Models/svm_use_data_lc.rds')

# Get the confusion matrix
svm.cm.lc <- caret::confusionMatrix(svm.model.lc$pred$pred, svm.model.lc$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.lc)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'Low Correlation'
                        ,Accuracy = svm.cm.lc$overall[1]
                        ,Kappa = svm.cm.lc$overall[2]
                        ,F1 = svm.cm.lc$byClass[7]
                        ,ROC = performance[,1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]))

rownames(svm_results) <- NULL

# Disable parallel processing and release resources
#stopCluster(cluster)
#registerDoSEQ()

```

```{r svm_roc, echo = FALSE}

kable(svm_results, caption = "SVM Model Results", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))

svm.ROC <- roc(svm.model.ud$pred$obs, svm.model.ud$pred$Normal)
plot(svm.ROC, col = 'blue', main = paste('SVM - Area under the curve (AUC):', round(auc(svm.ROC),2)))

```

