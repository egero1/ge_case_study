\subsection{Support Vector Machine} 

A Support Vector Machine [SVM] is a supervised machine learning algorithm defined by a separating hyperplane. In this algorithm, each data element is plotted in n-dimensional space, where is the number of features. Then classification is performed by finding the hyperplane that best differentiates the classes[@ray_2017]. SVM is a very popular modeling techhinque that often provides great results with very little tuning.

A radial basis function kernel (RBF) was selected to classify since the data is not linearly separable. The RBF is defined as:

$$f(x)=\sum_{i}^{N}\alpha _{i}y_{i} exp(-\left \| x-x_{i} \right \|^{2}/2\sigma ^2) + b$$

The RBF has two tuning parameters available through the 'caret' package. A wider or softer margin is created when C (cost) is decreased and that for larger values of $\sigma$ the decision boundary tends to be smoother and more flexible. It also tends to misclassify more often, but reduces the likelihood of overfitting the model [@wang_2014].

__Figure 10__ provides an example of the non-linear decision boundary. Note that the separation is less than ideal, but that is to be expected since these variables were selected at random and represent only part of the models separation capabilities. Unforunately, it is not possible to plot the separation planes in 16-dimensions.

```{r svm_bound_plot, echo = FALSE, out.width = '350px', fig.cap = 'Decision Boundaries', fig.align = "center", fig.pos = 'H'}

include_graphics("./Photos/svm_boundaries.jpg")

```

```{r svm_model, echo = FALSE}

# Create a data frame to hold the results
svm_results <- data.frame(Model = character()
                          ,Data = character()
                          ,Accuracy = numeric()
                          ,Sensitivity = numeric()
                          ,Specificity = numeric()
                          ,Precision = numeric()
                          ,Kappa = numeric()
                          ,F1 = numeric()
                          ,ROC = numeric())
```

```{r svm_models, echo = FALSE}
# Enable parallel processing and reserve resources
#cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
#registerDoParallel(cluster)


# Set up training conditions - must use LOOCV
fitControl <- trainControl(method = "LOOCV"
                           ,classProbs = TRUE 
                           ,summaryFunction = twoClassSummary
                           ,savePredictions = 'final')

# Full data set
#set.seed(1234)
#svm.model.ud <- caret::train(Label ~ .
#                          ,data = use_data 
#                          ,method = "svmRadial"
#                          ,trControl = fitControl
#                          ,metric = "Accuracy")

svm.model.ud <- readRDS('../../Models/svm_use_data.rds')

# Get the confusion matrix
svm.cm.ud <- caret::confusionMatrix(svm.model.ud$pred$pred, svm.model.ud$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.ud)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'Full'
                        ,Accuracy = svm.cm.ud$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = svm.cm.ud$byClass[5]
                        ,Kappa = svm.cm.ud$overall[2]
                        ,F1 = svm.cm.ud$byClass[7]
                        ,ROC = performance[,1]))

# RFE selection data set
#set.seed(1234)
#svm.model.md <- caret::train(Label ~ .
#                          ,data = model_data
#                          ,method = "svmRadial"
#                          ,trControl = fitControl
#                          ,metric = "Accuracy")

svm.model.md <- readRDS('../../Models/svm_model_data.rds')

# Get the confusion matrix
svm.cm.md <- caret::confusionMatrix(svm.model.md$pred$pred, svm.model.md$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.md)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'RFE Selection'
                        ,Accuracy = svm.cm.md$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = svm.cm.md$byClass[5]
                        ,Kappa = svm.cm.md$overall[2]
                        ,F1 = svm.cm.md$byClass[7]
                        ,ROC = performance[,1]))

# Low correlation data set
#set.seed(1234)
#svm.model.lc <- caret::train(Label ~ .
#                           ,data = use_data_lc
#                           ,method = "svmRadial"
#                           ,trControl = fitControl
#                           ,metric = "Accuracy")

svm.model.lc <- readRDS('../../Models/svm_use_data_lc.rds')

# Get the confusion matrix
svm.cm.lc <- caret::confusionMatrix(svm.model.lc$pred$pred, svm.model.lc$pred$obs, mode = "everything")

# Get the performance metrics from the model and save for comparison
performance <- getTrainPerf(svm.model.lc)
svm_results <- rbind(svm_results
                        ,data.frame(Model = 'SVM'
                        ,Data = 'Low Correlation'
                        ,Accuracy = svm.cm.lc$overall[1]
                        ,Sensitivity = performance[,2]
                        ,Specificity = performance[,3]
                        ,Precision = svm.cm.lc$byClass[5]
                        ,Kappa = svm.cm.lc$overall[2]
                        ,F1 = svm.cm.lc$byClass[7]
                        ,ROC = performance[,1]))

rownames(svm_results) <- NULL

# Disable parallel processing and release resources
#stopCluster(cluster)
#registerDoSEQ()

```

The evaluation metrics for the SVM models are available in __Table 11__. As with the GLM models, the full data set has a slight edge here with an accuracy of `r round(svm.cm.ud$overall[1] * 100, 2)`%. 

```{r svm_results, echo = FALSE}

kable(svm_results, caption = "SVM Model Results", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))
```

The confusion matrix for this model is available in __Table 12__. The model predicts Pneumoconiosis in 83 patients when no disease is actually present, and fails to predict the presence of Pneumoconiosis in 129 patients. 

```{r svm_table, echo = FALSE}

kable(glm.cm.ud$table, caption = "SVM Model Confusion Matrix", booktabs = TRUE) %>% 
        kable_styling(font_size = 8, latex_options = c("striped", "hold_position"))

svm.ROC <- roc(svm.model.ud$pred$obs, svm.model.ud$pred$Normal)
svm.auc <- auc(svm.ROC)

```

The AUC in __Figure 11__ of `r svm.auc` is a slight improvement over the best GLM model.  

```{r svm_roc, echo = FALSE, out.width = '350px', fig.cap = 'SVM ROC Curve', fig.align = "center", fig.pos = 'H'}

plot(svm.ROC, col = 'blue', main = paste('SVM - Area under the curve (AUC):', round(auc(svm.ROC),2)))

```

The SVM models do show an improvement, but not as much as hoped or expected. This is partially due to the use of LOOCV. Manually tuning this model would likely significantly improve the model's performance.